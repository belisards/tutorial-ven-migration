---
title: "Venezuelan in Chile, Colombia, Ecuador, and Peru"
format: 
  html:
    toc: true
    embed-resources: true
    toc_float: true
    code-tools: true
---

A step-by-step guide, using R to analyze statistics from host populations and Venezuelans in Chile, Colombia, Ecuador and Peru.

# Introduction

The World Bank report [Venezuelan in Chile, Colombia, Ecuador, and Peru](https://www.jointdatacenter.org/venezuela-migration-report/) provides a detailed socio-economic profile of Venezuelans in these four countries to help guide the policy and institutional response. The study uses official data from several surveys covering the adult population (18 years or older) of Venezuelan and national residents. The World Bank-UNHCR Joint Data Center on Forced Displacement supported the data collection and elaboration of the study and has created this tutorial to help process the data for your own purposes.

# Data sources

The following surveys are collated into four CSV table files - one per country -- which are cleaned and harmonized. That is, they are of similar structure and have the same variable names and values.

| [Country]{.underline} | [Survey]{.underline}                                                                  | [Modality]{.underline} |
|---------------|------------------------------------------|---------------|
| **Chile**             | Encuesta de Migración                                                                 | Telephone              |
| **Chile**             | Labor Survey                                                                          | In-person              |
| **Colombia**          | Gran Encuesta Integrada de Hogares (GEIH)                                             | In-person              |
| **Colombia**          | Migration Pulse (Round 4)                                                             | Telephone              |
| **Ecuador**           | Encuesta a Personas en Movilidad Humana y en Comunidades Receptoras en Ecuador (EPEC) | In-person              |
| **Ecuador**           | High-Frequency Phone Surveys (HFPS)                                                   | Telephone              |
| **Peru**              | Encuesta Nacional de Hogares (ENAHO)                                                  | In-person              |
| **Peru**              | Encuesta Dirigida a la Población Venezolana (ENPOVE)                                  | In-person              |

# How to analyze survey data using open-source solutions?

Survey data have unique characteristics that set them apart from other data sources. A weight is assigned to each observation which allows the inferences from a limited and biased sample to be made. Weighted values are crucial to make an inference from the sample (Venezuelans and hosts that responded to the surveys) to the population (all Venezuelans and hosts).

Although proprietary software analyzes weighted surveys with graphic interfaces, open-source tools present more challenges for beginners. The most common approach requires knowledge of [programming languages like R](https://www.r-project.org/), which is designed for statistical analysis and provides a range of ways to analyze survey data. If you are unfamiliar with R, you can download [RStudio](https://posit.co/download/rstudio-desktop/) and use an [introductory video](https://www.youtube.com/watch?v=FIrsOBy5k58) to install it and run your first R codes.

# Analyzing the data using R

The examples below use R to conduct basic analysis on the microdata in the report [**Venezuelan in Chile, Colombia, Ecuador, and Peru**](https://www.jointdatacenter.org/venezuela-migration-report/).

Different styles represent R code and its outputs. For example, the code with a [`print`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/print) command below shows the message quoted as an output.

```{r}
print("Coding is easy!")
```

### Load libraries

First, we will load the libraries needed for our tutorial using the [`library`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/library) command. We explain the main purpose of each one as comments placed after the hashtag (`#`).

```{r}
#| output: false
library(survey) # to handle survey weights
library(tidyverse) # to manipulate data easily
library(visdat) # to visualize missing values
library(knitr) # to format output nicely
```

### How to read the data

To read the survey data and inspect the information available, we use the dataset for Ecuador as an example.

```{r}
file_name = "https://www.jointdatacenter.org/wp-content/uploads/2024/02/ecu_host_mig.csv" 

survey = read.csv(file_name)
```

You can select data for a different country by changing the URL after the `file_name` variable. All datasets and data dictionaries are available on our website: <https://www.jointdatacenter.org/venezuelan-migration-data/>

To choose a country other than Ecuador, visit the page above, right-click on "Cleaned survey data (CSV)", choose "Copy link address", and change the URL, ensuring the quotes are preserved.

In the second line of the code block above, the [`read.csv`](https://www.rdocumentation.org/packages/qtl2/versions/0.32/topics/read_csv) command loads the data in the URL or file path specified in the first line.

Next, check the number of rows (observations), columns (variables), their respective data types and some sample values.

```{r}

str(survey) # print the survey STRucture

```

It shows there are `r nrow(survey)` rows and `r ncol(survey)` columns. The output also shows the column names after the dollar sign, the data type (`int` and `num` for numeric values, `chr` for text strings) and values from the first rows.

Variables that have missing values are represented by NA for numeric variables and empty quotes for categorical.

The [`str()`](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/str) function provides a concise summary of the dataset, showing its data type, dimensions, and content.

## Preliminary analysis

To understand how each country file is structured, review some core variables. You can find detailed descriptions for all available variables in the data dictionaries ([codebooks](https://www.jointdatacenter.org/venezuelan-migration-data/)).

-   `survey`: the name of the survey;

-   `wave`: the wave of the survey. Surveys might have more than one round, known as waves. Each wave is collected in a distinct period of time.

-   `samp`: indicate whether the response comes from Venezuelan or the host population;

-   `weight`: the weight assigned for each record to produce unbiased estimates;

Each file aggregates different surveys from the same country. Therefore, you should use the variables `survey` and `wave` to filter the data and pick the right source depending on your question. Because distinct surveys cover different questions, some rows have missing values.

### How to inspect missing values

To identify the missing information, plot the values for each column and surveys. The chart shows more records from the *Encuesta de personas en Movilidad y Comunidades de Acogida* (EPEC) survey than *High-Frequency Phone Surveys* (HFPS). The highlighted regions make it easy to spot which variables have missing values.

The [`vis_miss()`](https://www.rdocumentation.org/packages/visdat/versions/0.6.0/topics/vis_miss) function is used to visualize missing data in a dataset. It takes the dataset `survey`\` as the first parameter and a column to group (facet) the observations.

```{r, fig.width=9}
visdat::vis_miss(survey,facet = survey)
```

To keep it simple, our tutorial analyses only information on age, marital status, region, and population type (host or Venezuelan) in the HPFS survey. As the image shows, these variables have no missing values.

Missing values are crucial to the data preparation phase. You might need to drop missing values or impute values to conduct other analyses. Your chosen strategy depends on why values are missing, the number of missing values, and your analytical goals. Refer to the data dictionary and documentation to understand the reasons for missing values.

### Records by surveys and waves

Before applying the weights, we will check the total number of respondents by survey, wave and population.

The [`group_by`](https://www.rdocumentation.org/packages/dplyr/versions/0.2/topics/group_by) function is used to group data by one or more variables. This command doesn't change the dataset; rather, it sets up a new configuration for subsequent operations within each group. The [`summarise`](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/summarise) function is used to compute summary statistics or metrics for each group. Finally, the [`kable()`](https://www.rdocumentation.org/packages/knitr/versions/1.45/topics/kable) function presents the result better than the standard output.

```{r}
summary_df <- survey %>% 
  group_by(survey, wave, samp) %>% 
  summarise(total = n(), .groups = 'drop')

```

```{r}
# Show the table
kable(summary_df, caption = "Number of records by survey, wave and population")

```

So far, the dataset reflects the number of responses from an unweighted sample of Venezuelan and host population. Next, we demonstrate how to use weights to calculate representative estimates.

## Configure the survey design

As different surveys present distinct questions, select the survey according to the goals of your analysis. Most of the indicators from Ecuador come from the HFPS, except those referring to job occupations and health insurance, which come from the EPEC survey.

Select the HFPS survey to calculate and compare the average age of Venezuelan and the host population in Ecuador. Let's start filtering the dataset to get only observations from the HFPS using the [`filter()`](https://www.rdocumentation.org/packages/dplyr/versions/0.7.8/topics/filter) function.

```{r}
survey_filter <- survey %>% 
  filter(survey == "HFPS")

```

Next, we load the survey design and the weights associated with each response. There are a variety of ways to implement weighted data analysis using R. For convenience, we use the function [`svydesign`](https://www.rdocumentation.org/packages/survey/versions/4.4-1/topics/svydesign) from [`survey`](https://cran.r-project.org/package=survey), an R package with pre-built features tailored for survey analysis. It allows for the specification of survey design parameters such as sampling weights.

```{r}
survey_ecu <- svydesign(ids = ~1, # ~1 means the survey has no clusters
                       data= survey_filter, 
                       weights = survey_filter$weight)

```

## Descriptive statistic

Creating basic summary statistics using the `survey` package is straightforward. Our tutorial shows how to group observations and analyze numeric and categorical variables. If you group by region (the column `code_province`), bear in mind that the weights are not meant for this level of disaggregation, and the estimates may not accurately reflect the characteristics of these populations in each region.

### Numeric values

The [`svyby`](https://www.rdocumentation.org/packages/survey/versions/4.2-1/topics/svyby) function is used to apply a function to subsets of survey data defined by one or more variables. We will use it to group the records by the population type (`~samp`) and calculate the mean age ([`svymean`](https://www.rdocumentation.org/packages/survey/versions/2.8-1/topics/surveysummary)).

The output shows the mean and the standard error (`se`) for each estimate. Standard error values use the same unit of measurement as the mean. They represent how much the sample mean calculated is expected to vary from the actual population mean.

```{r}
# Group by and calculate the mean age
svyby(formula = ~age, by = ~samp, design = survey_ecu, svymean)

```

### Categoric variables

The `svytable` function is used to create contingency tables for survey data, taking into account survey design features such as sampling weights. Next, we use it to analyze marital status.

Using [`prop.table(crosstab, 1)`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/prop.table), we present the values as percentages of the population/row level (using 0 instead of 1 in the command would sum the values to 100 across columns). Additionally, we round the values to two decimal places with [`round()`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/Round).

```{r}
# Cross-tabulates values
crosstab <- svytable(~samp + marital_status, design = survey_ecu)

```

```{r}
# Calculate percentages
crosstab_percentages <- round(prop.table(crosstab,1) * 100,2) 
 
```

```{r}
# Show the table
knitr::kable(crosstab_percentages, 
             caption = "Crosstab of Occupation by Marital Status (%)")

```

# Conclusion

This tutorial has offered a glimpse into the initial steps for leveraging open-source tools to analyze survey data. While we have covered essential techniques, the scope for further exploration is vast.

We invite you to share open-source solutions to analyze weighted survey data that might have been overlooked or suggest topics for future tutorials on forced displacement data. Contact us by email or social media networks ([Twitter](https://twitter.com/jointdatacenter) and [LinkedIn](https://www.linkedin.com/company/joint-data-center/)).

# Extra resources

<https://github.com/pewresearch/pewmethods>: R package developed by the Pew Research Center Methods team to work with survey data.

<https://github.com/quantipy/quantipy3/>: Python package to read survey data.
